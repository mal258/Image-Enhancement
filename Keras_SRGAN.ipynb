{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilalithaveerubhotla/Image-Enhancement/blob/main/Keras_SRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj-ibxMvYsfA"
      },
      "source": [
        "### Super Resolution GAN for converting Low resolution images to High resolution images \n",
        "\n",
        "\n",
        "### Trained with 5000 training images and 800 test images on CIFAR10 dataset,with 2 epochs. SRGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSZtOsQwXz8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e259024b-5df1-4629-ef0f-efea42c241ae"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/SRGAN')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOlAxVHWZ7Px"
      },
      "source": [
        "#git clone to Keras SRGAN (extremely important as Network.py is imported from here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QParVa7bWri3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03127659-a422-4963-b453-7a469dbf29f8"
      },
      "source": [
        "!git clone https://github.com/deepak112/Keras-SRGAN.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Keras-SRGAN' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K6uCqIMaJOA"
      },
      "source": [
        "#cd to Keras-SRGAN and do ls to make sure Newtork.py is present"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aZb3sEjW1Ib"
      },
      "source": [
        "!cd Keras-SRGAN\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsSIb84UY2Im"
      },
      "source": [
        "# Dataset CIFAR10 split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB2otx0lVn7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f2f8a4-e6e3-4216-bcfd-2dbfed583e0a"
      },
      "source": [
        "from keras.datasets import cifar10                     #dataset importing \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train=x_train[0:5000]\n",
        "x_test=x_test[0:800]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 14s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNKlMJVwShWl"
      },
      "source": [
        "# Generator and discriminator blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZzF6IyaQ0tF"
      },
      "source": [
        "#Network.py\n",
        "from keras.layers import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.layers import add\n",
        "\n",
        "\n",
        "# Residual block\n",
        "def res_block_gen(model, kernal_size, filters, strides):\n",
        "    \n",
        "    gen = model\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    # Using Parametric ReLU\n",
        "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "        \n",
        "    model = add([gen, model])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    \n",
        "def up_sampling_block(model, kernal_size, filters, strides):\n",
        "    \n",
        "    # In place of Conv2D and UpSampling2D we can also use Conv2DTranspose (Both are used for Deconvolution)\n",
        "    # Even we can have our own function for deconvolution (i.e one made in Utils.py)\n",
        "    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = UpSampling2D(size = 2)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_block(model, filters, kernel_size, strides):\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
        "class Generator(object):\n",
        "\n",
        "    def __init__(self, noise_shape):\n",
        "        \n",
        "        self.noise_shape = noise_shape\n",
        "\n",
        "    def generator(self):\n",
        "        \n",
        "\t    gen_input = Input(shape = self.noise_shape)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
        "\t    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "\t    \n",
        "\t    gen_model = model\n",
        "        \n",
        "        # Using 16 Residual Blocks\n",
        "\t    for index in range(16):\n",
        "\t        model = res_block_gen(model, 3, 64, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model)\n",
        "\t    model = BatchNormalization(momentum = 0.5)(model)\n",
        "\t    model = add([gen_model, model])\n",
        "\t    \n",
        "\t    # Using 2 UpSampling Blocks\n",
        "\t    for index in range(2):\n",
        "\t        model = up_sampling_block(model, 3, 256, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(model)\n",
        "\t    model = Activation('tanh')(model)\n",
        "\t   \n",
        "\t    generator_model = Model(inputs = gen_input, outputs = model)\n",
        "        \n",
        "\t    return generator_model\n",
        "\n",
        "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
        "class Discriminator(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "    \n",
        "    def discriminator(self):\n",
        "        \n",
        "        dis_input = Input(shape = self.image_shape)\n",
        "        \n",
        "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        model = discriminator_block(model, 64, 3, 2)\n",
        "        model = discriminator_block(model, 128, 3, 1)\n",
        "        model = discriminator_block(model, 128, 3, 2)\n",
        "        model = discriminator_block(model, 256, 3, 1)\n",
        "        model = discriminator_block(model, 256, 3, 2)\n",
        "        model = discriminator_block(model, 512, 3, 1)\n",
        "        model = discriminator_block(model, 512, 3, 2)\n",
        "        \n",
        "        model = Flatten()(model)\n",
        "        model = Dense(1024)(model)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "       \n",
        "        model = Dense(1)(model)\n",
        "        model = Activation('sigmoid')(model) \n",
        "        \n",
        "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
        "        \n",
        "        return discriminator_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTq2CZypSUa1"
      },
      "source": [
        "# Loss function and Image generation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_9NpqVeRFfo"
      },
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "class VGG_LOSS(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    # computes VGG loss or content loss\n",
        "    def vgg_loss(self, y_true, y_pred):\n",
        "    \n",
        "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
        "        vgg19.trainable = False\n",
        "        # Make trainable as False\n",
        "        for l in vgg19.layers:\n",
        "            l.trainable = False\n",
        "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
        "        model.trainable = False\n",
        "    \n",
        "        return K.mean(K.square(model(y_true) - model(y_pred)))\n",
        "    \n",
        "def get_optimizer():\n",
        " \n",
        "    adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "    return adam\n",
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        "from skimage import data, io, filters\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy.random import randint\n",
        "#from scipy.misc import imread\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "# Subpixel Conv will upsample from (h, w, c) to (h/r, w/r, c/r^2)\n",
        "def SubpixelConv2D(input_shape, scale=4):\n",
        "    def subpixel_shape(input_shape):\n",
        "        dims = [input_shape[0],input_shape[1] * scale,input_shape[2] * scale,int(input_shape[3] / (scale ** 2))]\n",
        "        output_shape = tuple(dims)\n",
        "        return output_shape\n",
        "    \n",
        "    def subpixel(x):\n",
        "        return tf.depth_to_space(x, scale)\n",
        "        \n",
        "    return Lambda(subpixel, output_shape=subpixel_shape)\n",
        "    \n",
        "# Takes list of images and provide HR images in form of numpy array\n",
        "def hr_images(images):\n",
        "    images_hr = array(images)\n",
        "    return images_hr\n",
        "\n",
        "# Takes list of images and provide LR images in form of numpy array\n",
        "def lr_images(images_real , downscale):\n",
        "    \n",
        "    images = []\n",
        "    for img in  range(len(images_real)):\n",
        "        images.append(cv2.resize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interp='bicubic', mode=None))\n",
        "    images_lr = array(images)\n",
        "    return images_lr\n",
        "    \n",
        "def normalize(input_data):\n",
        "\n",
        "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
        "    \n",
        "def denormalize(input_data):\n",
        "    input_data = (input_data + 1) * 127.5\n",
        "    return input_data.astype(np.uint8)\n",
        "   \n",
        " \n",
        "def load_path(path):\n",
        "    directories = []\n",
        "    if os.path.isdir(path):\n",
        "        directories.append(path)\n",
        "    for elem in os.listdir(path):\n",
        "        if os.path.isdir(os.path.join(path,elem)):\n",
        "            directories = directories + load_path(os.path.join(path,elem))\n",
        "            directories.append(os.path.join(path,elem))\n",
        "    return directories\n",
        "    \n",
        "def load_data_from_dirs(dirs, ext):\n",
        "    files = []\n",
        "    file_names = []\n",
        "    count = 0\n",
        "    for d in dirs:\n",
        "        for f in os.listdir(d): \n",
        "            if f.endswith(ext):\n",
        "                image = data.imread(os.path.join(d,f))\n",
        "                if len(image.shape) > 2:\n",
        "                    files.append(image)\n",
        "                    file_names.append(os.path.join(d,f))\n",
        "                    \n",
        "                count = count + 1\n",
        "    return files     \n",
        "\n",
        "def load_data(directory, ext):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    return files\n",
        "    \n",
        "def load_training_data(directory, ext, number_of_images = 1000, train_test_ratio = 0.8):\n",
        "\n",
        "    number_of_train_images = int(number_of_images * train_test_ratio)\n",
        "    \n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    test_array = array(files)\n",
        "    if len(test_array.shape) < 3:\n",
        "        print(\"Images are of not same shape\")\n",
        "        print(\"Please provide same shape images\")\n",
        "        sys.exit()\n",
        "    \n",
        "    x_train = files[:number_of_train_images]\n",
        "    x_test = files[number_of_train_images:number_of_images]\n",
        "    \n",
        "    x_train_hr = hr_images(x_train)\n",
        "    x_train_hr = normalize(x_train_hr)\n",
        "    \n",
        "    x_train_lr = lr_images(x_train, 4)\n",
        "    x_train_lr = normalize(x_train_lr)\n",
        "    \n",
        "    x_test_hr = hr_images(x_test)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(x_test, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
        "\n",
        "\n",
        "def load_test_data_for_model(directory, ext, number_of_images = 100):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    x_test_hr = hr_images(files)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(files, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_test_lr, x_test_hr\n",
        "    \n",
        "def load_test_data(directory, ext, number_of_images = 100):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    x_test_lr = lr_images(files, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_test_lr\n",
        "    \n",
        "# While training save generated image(in form LR, SR, HR)\n",
        "# Save only one image as sample  \n",
        "def plot_generated_images(output_dir, epoch, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    \n",
        "    examples = x_test_hr.shape[0]\n",
        "    print(examples)\n",
        "    value = randint(0, examples)\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 1)\n",
        "    plt.imshow(image_batch_lr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(dim[0], dim[1], 2)\n",
        "    plt.imshow(generated_image[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 3)\n",
        "    plt.imshow(image_batch_hr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir + 'generated_image_%d.png' % epoch)\n",
        "    \n",
        "    #plt.show()\n",
        "    \n",
        "# Plots and save generated images(in form LR, SR, HR) from model to test the model \n",
        "# Save output for all images given for testing  \n",
        "def plot_test_generated_images_for_model(output_dir, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    \n",
        "    examples = x_test_hr.shape[0]\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 1)\n",
        "        plt.imshow(image_batch_lr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(dim[0], dim[1], 2)\n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 3)\n",
        "        plt.imshow(image_batch_hr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'test_generated_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()\n",
        "\n",
        "# Takes LR images and save respective HR images\n",
        "def plot_test_generated_images(output_dir, generator, x_test_lr, figsize=(5, 5)):\n",
        "    \n",
        "    examples = x_test_lr.shape[0]\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        #plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE8GR87RR1MM"
      },
      "source": [
        "# Training code . Please change the output dir in the last line. According to where you want to save the weights. This has 500 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzToB57lROep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2630d9-3cbb-484d-d311-1b03d865ec8b"
      },
      "source": [
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        "from skimage import data, io, filters\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy.random import randint\n",
        "#from scipy.misc import imread\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Subpixel Conv will upsample from (h, w, c) to (h/r, w/r, c/r^2)\n",
        "def SubpixelConv2D(input_shape, scale=4):\n",
        "    def subpixel_shape(input_shape):\n",
        "        dims = [input_shape[0],input_shape[1] * scale,input_shape[2] * scale,int(input_shape[3] / (scale ** 2))]\n",
        "        output_shape = tuple(dims)\n",
        "        return output_shape\n",
        "    \n",
        "    def subpixel(x):\n",
        "        return tf.depth_to_space(x, scale)\n",
        "        \n",
        "    return Lambda(subpixel, output_shape=subpixel_shape)\n",
        "    \n",
        "# Takes list of images and provide HR images in form of numpy array\n",
        "def hr_images(images):\n",
        "    images_hr = array(images)\n",
        "    return images_hr\n",
        "\n",
        "# Takes list of images and provide LR images in form of numpy array\n",
        "def lr_images(images_real , downscale):\n",
        "    \n",
        "    images= []\n",
        "    \n",
        "      \n",
        "    for img in  range(len(images_real)):\n",
        "        #images.append(cv2.resize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interpolation='bicubic', mode=None))\n",
        "        im123=cv2.resize(images_real[img], (int(images_real[img].shape[0]//downscale),int(images_real[img].shape[1]//downscale)))\n",
        "        images.append(im123)\n",
        "    images_lr = array(images)\n",
        "    return images_lr\n",
        "    \n",
        "def normalize(input_data):\n",
        "\n",
        "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
        "    \n",
        "def denormalize(input_data):\n",
        "    input_data = (input_data + 1) * 127.5\n",
        "    return input_data.astype(np.uint8)\n",
        "   \n",
        "\n",
        "    \n",
        "def load_training_data(x_train,y_train,x_test,y_test):\n",
        "\n",
        "    number_of_train_images = x_test.shape[0]\n",
        "    \n",
        "    #files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    #if len(files) < number_of_images:\n",
        "     #   print(\"Number of image files are less then you specified\")\n",
        "      #  print(\"Please reduce number of images to %d\" % len(files))\n",
        "       # sys.exit()\n",
        "        \n",
        "   # test_array = array(files)\n",
        "   # if len(test_array.shape) < 3:\n",
        "    #    print(\"Images are of not same shape\")\n",
        "     #   print(\"Please provide same shape images\")\n",
        "      #  sys.exit()\n",
        "    \n",
        "   \n",
        "\n",
        "    x_train_hr = hr_images(x_train)\n",
        "    x_train_hr = normalize(x_train_hr)\n",
        "    \n",
        "    x_train_lr = lr_images(x_train, 4)\n",
        "    x_train_lr = normalize(x_train_lr)\n",
        "    \n",
        "    x_test_hr = hr_images(x_test)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(x_test, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
        "\n",
        "\n",
        "    \n",
        "# While training save generated image(in form LR, SR, HR)\n",
        "# Save only one image as sample  \n",
        "def plot_generated_images(output_dir, epoch, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    print(\"In plot test generated images\")\n",
        "    examples = x_test_hr.shape[0]\n",
        "    print(examples)\n",
        "    value = randint(0, examples)\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 1)\n",
        "    plt.imshow(image_batch_lr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(dim[0], dim[1], 2)\n",
        "    plt.imshow(generated_image[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 3)\n",
        "    plt.imshow(image_batch_hr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir + 'generated_image_%d.png' % epoch)\n",
        "    \n",
        "    #plt.show()\n",
        "    \n",
        "# Plots and save generated images(in form LR, SR, HR) from model to test the model \n",
        "# Save output for all images given for testing  \n",
        "def plot_test_generated_images_for_model(output_dir, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    \n",
        "    examples = x_test_hr.shape[0]\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 1)\n",
        "        plt.imshow(image_batch_lr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(dim[0], dim[1], 2)\n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 3)\n",
        "        plt.imshow(image_batch_hr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'test_generated_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()\n",
        "\n",
        "# Takes LR images and save respective HR images\n",
        "def plot_test_generated_images(output_dir, generator, x_test_lr, figsize=(5, 5)):\n",
        "    \n",
        "    examples = x_test_lr.shape[0]\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        #plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)    \n",
        "    \n",
        "        #plt.show()\n",
        "\n",
        "###############################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "np.random.seed(10)\n",
        "# Better to use downscale factor as 4\n",
        "downscale_factor = 4\n",
        "# Remember to change image shape if you are having different size of images\n",
        "image_shape = (32,32,3)\n",
        "\n",
        "# Combined network\n",
        "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=shape)\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x) #Here I think there should be two inputs to discriminator x and another hr image\n",
        "    # and like this only the discriminator model should also be modified\n",
        "    gan = Model(inputs=gan_input, outputs=[x,gan_output])    #And why is there two outputs of the gan_model overall\n",
        "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
        "                loss_weights=[1., 1e-3],\n",
        "                optimizer=optimizer)\n",
        "\n",
        "    return gan\n",
        "\n",
        "# default values for all parameters are given, if want defferent values you can give via commandline\n",
        "# for more info use $python train.py -h\n",
        "def train(epochs, batch_size, x_train,y_train,x_test,y_test, model_save_dir):\n",
        "    \n",
        "    x_train_lr, x_train_hr, x_test_lr, x_test_hr = load_training_data(x_train,y_train,x_test,y_test) \n",
        "    loss = VGG_LOSS(image_shape)  \n",
        "    \n",
        "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
        "    shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
        "    \n",
        "    generator = Generator(shape).generator()\n",
        "    discriminator = Discriminator(image_shape).discriminator()\n",
        "\n",
        "    optimizer = get_optimizer()\n",
        "    generator.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "    \n",
        "    gan = get_gan_network(discriminator, shape, generator, optimizer, loss.vgg_loss)\n",
        "    \n",
        "    loss_file = open(model_save_dir + 'losses.txt' , 'w+')\n",
        "    loss_file.close()\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            \n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "           \n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "            print(image_batch_lr.shape)\n",
        "            generated_images_sr = generator.predict(image_batch_lr)\n",
        "\n",
        "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "            \n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
        "            discriminator_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            discriminator.trainable = False\n",
        "            gan_loss = gan.train_on_batch(image_batch_lr, [image_batch_hr,gan_Y])\n",
        "            \n",
        "            \n",
        "        print(\"discriminator_loss : %f\" % discriminator_loss)\n",
        "        print(\"gan_loss :\", gan_loss)\n",
        "        gan_loss = str(gan_loss)\n",
        "        \n",
        "        loss_file = open(model_save_dir + 'losses.txt' , 'a')\n",
        "        loss_file.write('epoch%d : gan_loss = %s ; discriminator_loss = %f\\n' %(e, gan_loss, discriminator_loss) )\n",
        "        loss_file.close()\n",
        "\n",
        "        if e == 1 or e % 5 == 0:\n",
        "            plot_generated_images(model_save_dir, e, generator, x_test_hr, x_test_lr)\n",
        "        if e % 1 == 0:\n",
        "            \n",
        "            generator.save(model_save_dir + 'gen_model%d.h5' % e)       \n",
        "            discriminator.save(model_save_dir + 'dis_model%d.h5' % e)\n",
        "            print(\"Model saved\")\n",
        "    \n",
        "train(1, 64, x_train,y_train,x_test,y_test, '/content/drive/My Drive/SRGAN/')                 #last parameter is to save the image to the path specified\n",
        "\n",
        "#train(no_of_epochs,batch_size,x_train,y_train,x_test,y_test,path_name of model saving)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/78 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 1 ---------------\n",
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 1/78 [00:36<46:19, 36.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 2/78 [01:10<45:06, 35.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 3/78 [01:45<44:22, 35.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 4/78 [02:20<43:23, 35.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 5/78 [02:55<42:40, 35.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 6/78 [03:30<42:10, 35.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 7/78 [04:05<41:41, 35.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 8/78 [04:42<41:33, 35.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 9/78 [05:18<41:03, 35.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 10/78 [05:54<40:44, 35.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 11/78 [06:30<40:03, 35.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 12/78 [07:06<39:27, 35.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 13/78 [07:41<38:48, 35.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 14/78 [08:18<38:28, 36.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 15/78 [08:56<38:20, 36.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 16/78 [09:31<37:20, 36.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 17/78 [10:06<36:32, 35.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 18/78 [10:43<36:02, 36.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 19/78 [11:19<35:24, 36.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 20/78 [11:55<35:02, 36.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 21/78 [12:32<34:28, 36.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 22/78 [13:07<33:30, 35.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 23/78 [13:42<32:43, 35.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 24/78 [14:17<32:00, 35.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 25/78 [14:53<31:23, 35.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 26/78 [15:28<30:37, 35.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 27/78 [16:03<29:58, 35.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 28/78 [16:38<29:24, 35.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 29/78 [17:13<28:41, 35.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 30/78 [17:48<28:02, 35.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 31/78 [18:22<27:20, 34.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 32/78 [18:59<27:16, 35.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 33/78 [19:35<26:38, 35.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▎     | 34/78 [20:10<26:03, 35.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 35/78 [20:46<25:26, 35.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 36/78 [21:21<24:43, 35.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 37/78 [22:01<25:11, 36.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▊     | 38/78 [22:37<24:25, 36.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 39/78 [23:13<23:35, 36.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 40/78 [23:48<22:45, 35.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 41/78 [24:24<22:15, 36.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 42/78 [24:59<21:22, 35.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 43/78 [25:34<20:39, 35.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 44/78 [26:09<20:00, 35.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 45/78 [26:43<19:16, 35.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 46/78 [27:18<18:41, 35.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 47/78 [27:54<18:08, 35.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 48/78 [28:29<17:35, 35.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 49/78 [29:06<17:15, 35.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 50/78 [29:43<16:54, 36.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 51/78 [30:18<16:07, 35.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 52/78 [30:54<15:28, 35.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 53/78 [31:29<14:46, 35.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 54/78 [32:04<14:10, 35.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 55/78 [32:39<13:32, 35.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 56/78 [33:15<12:58, 35.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 57/78 [33:50<12:23, 35.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 58/78 [34:25<11:48, 35.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 59/78 [35:01<11:15, 35.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 60/78 [35:36<10:36, 35.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 61/78 [36:12<10:03, 35.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 62/78 [36:47<09:25, 35.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 63/78 [37:25<09:00, 36.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 64/78 [38:00<08:21, 35.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 65/78 [38:36<07:47, 35.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▍ | 66/78 [39:14<07:16, 36.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 67/78 [39:50<06:41, 36.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 68/78 [40:26<06:01, 36.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 69/78 [41:01<05:23, 35.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|████████▉ | 70/78 [41:37<04:46, 35.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 71/78 [42:12<04:10, 35.74s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 72/78 [42:49<03:35, 35.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▎| 73/78 [43:25<03:00, 36.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▍| 74/78 [44:01<02:24, 36.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 75/78 [44:36<01:47, 35.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 76/78 [45:13<01:12, 36.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▊| 77/78 [45:48<00:35, 35.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [46:24<00:00, 35.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator_loss : 0.346830\n",
            "gan_loss : [0.07546138018369675, 0.07462482154369354, 0.8365601301193237]\n",
            "In plot test generated images\n",
            "800\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEDY70A0sTi5"
      },
      "source": [
        "def plot_test_generated_images_new(output_dir, generator, x_test_lr, figsize=(5, 5)):\n",
        "    \n",
        "    examples = 1\n",
        "    print(examples)\n",
        "    x_test_lr.resize(1,x_test_lr.shape[0],x_test_lr.shape[1],x_test_lr.shape[2])\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    generator.load_weights(output_dir + 'gen_model1.h5')\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        #plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)    \n",
        "    \n",
        "        plt.show()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyy7BCVWnxnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5310703-5520-4088-c1e5-5e993f3497a3"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img=cv2.imread('/content/drive/My Drive/IMG_6086.jpg')\n",
        "\n",
        "#img.resize(1,img.shape[0],img.shape[1],img.shape[2])\n",
        "shape=img.shape\n",
        "#print(shape)\n",
        "generator = Generator(shape).generator()\n",
        "plot_test_generated_images_new('/content/drive/My Drive/SRGAN/', generator,img, figsize=(5, 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ZghCdVJMHZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}