{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilalithaveerubhotla/Image-Enhancement/blob/main/Keras_SRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj-ibxMvYsfA"
      },
      "source": [
        "Trained with 5000 training images and 800 test images on CIFAR10 dataset,with 2 epochs. SRGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSZtOsQwXz8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd1e50c-a58b-481e-fad7-c010f4c4c8dd"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/SRGAN')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOlAxVHWZ7Px"
      },
      "source": [
        "#git clone to Keras SRGAN (extremely important as Network.py is imported from here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QParVa7bWri3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35184fa-1e66-45c1-d91f-213122aa9cfb"
      },
      "source": [
        "!git clone https://github.com/deepak112/Keras-SRGAN.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Keras-SRGAN' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K6uCqIMaJOA"
      },
      "source": [
        "#cd to Keras-SRGAN and do ls to make sure Newtork.py is present"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aZb3sEjW1Ib"
      },
      "source": [
        "!cd Keras-SRGAN\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsSIb84UY2Im"
      },
      "source": [
        "# Dataset CIFAR10 split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB2otx0lVn7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efff3da6-f0ea-45f0-90ee-6f20a35d9a14"
      },
      "source": [
        "from keras.datasets import cifar10                     #dataset importing \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train=x_train[0:5000]\n",
        "x_test=x_test[0:800]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNKlMJVwShWl"
      },
      "source": [
        "# Generator and discriminator blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZzF6IyaQ0tF"
      },
      "source": [
        "#Network.py\n",
        "from keras.layers import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.layers import add\n",
        "\n",
        "\n",
        "# Residual block\n",
        "def res_block_gen(model, kernal_size, filters, strides):\n",
        "    \n",
        "    gen = model\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    # Using Parametric ReLU\n",
        "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "        \n",
        "    model = add([gen, model])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    \n",
        "def up_sampling_block(model, kernal_size, filters, strides):\n",
        "    \n",
        "    # In place of Conv2D and UpSampling2D we can also use Conv2DTranspose (Both are used for Deconvolution)\n",
        "    # Even we can have our own function for deconvolution (i.e one made in Utils.py)\n",
        "    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = UpSampling2D(size = 2)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_block(model, filters, kernel_size, strides):\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
        "class Generator(object):\n",
        "\n",
        "    def __init__(self, noise_shape):\n",
        "        \n",
        "        self.noise_shape = noise_shape\n",
        "\n",
        "    def generator(self):\n",
        "        \n",
        "\t    gen_input = Input(shape = self.noise_shape)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
        "\t    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "\t    \n",
        "\t    gen_model = model\n",
        "        \n",
        "        # Using 16 Residual Blocks\n",
        "\t    for index in range(16):\n",
        "\t        model = res_block_gen(model, 3, 64, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model)\n",
        "\t    model = BatchNormalization(momentum = 0.5)(model)\n",
        "\t    model = add([gen_model, model])\n",
        "\t    \n",
        "\t    # Using 2 UpSampling Blocks\n",
        "\t    for index in range(2):\n",
        "\t        model = up_sampling_block(model, 3, 256, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(model)\n",
        "\t    model = Activation('tanh')(model)\n",
        "\t   \n",
        "\t    generator_model = Model(inputs = gen_input, outputs = model)\n",
        "        \n",
        "\t    return generator_model\n",
        "\n",
        "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
        "class Discriminator(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "    \n",
        "    def discriminator(self):\n",
        "        \n",
        "        dis_input = Input(shape = self.image_shape)\n",
        "        \n",
        "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        model = discriminator_block(model, 64, 3, 2)\n",
        "        model = discriminator_block(model, 128, 3, 1)\n",
        "        model = discriminator_block(model, 128, 3, 2)\n",
        "        model = discriminator_block(model, 256, 3, 1)\n",
        "        model = discriminator_block(model, 256, 3, 2)\n",
        "        model = discriminator_block(model, 512, 3, 1)\n",
        "        model = discriminator_block(model, 512, 3, 2)\n",
        "        \n",
        "        model = Flatten()(model)\n",
        "        model = Dense(1024)(model)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "       \n",
        "        model = Dense(1)(model)\n",
        "        model = Activation('sigmoid')(model) \n",
        "        \n",
        "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
        "        \n",
        "        return discriminator_model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTq2CZypSUa1"
      },
      "source": [
        "# Loss function and Image generation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_9NpqVeRFfo"
      },
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "class VGG_LOSS(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    # computes VGG loss or content loss\n",
        "    def vgg_loss(self, y_true, y_pred):\n",
        "    \n",
        "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
        "        vgg19.trainable = False\n",
        "        # Make trainable as False\n",
        "        for l in vgg19.layers:\n",
        "            l.trainable = False\n",
        "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
        "        model.trainable = False\n",
        "    \n",
        "        return K.mean(K.square(model(y_true) - model(y_pred)))\n",
        "    \n",
        "def get_optimizer():\n",
        " \n",
        "    adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "    return adam\n",
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        "from skimage import data, io, filters\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy.random import randint\n",
        "#from scipy.misc import imread\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "# Subpixel Conv will upsample from (h, w, c) to (h/r, w/r, c/r^2)\n",
        "def SubpixelConv2D(input_shape, scale=4):\n",
        "    def subpixel_shape(input_shape):\n",
        "        dims = [input_shape[0],input_shape[1] * scale,input_shape[2] * scale,int(input_shape[3] / (scale ** 2))]\n",
        "        output_shape = tuple(dims)\n",
        "        return output_shape\n",
        "    \n",
        "    def subpixel(x):\n",
        "        return tf.depth_to_space(x, scale)\n",
        "        \n",
        "    return Lambda(subpixel, output_shape=subpixel_shape)\n",
        "    \n",
        "# Takes list of images and provide HR images in form of numpy array\n",
        "def hr_images(images):\n",
        "    images_hr = array(images)\n",
        "    return images_hr\n",
        "\n",
        "# Takes list of images and provide LR images in form of numpy array\n",
        "def lr_images(images_real , downscale):\n",
        "    \n",
        "    images = []\n",
        "    for img in  range(len(images_real)):\n",
        "        images.append(cv2.resize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interp='bicubic', mode=None))\n",
        "    images_lr = array(images)\n",
        "    return images_lr\n",
        "    \n",
        "def normalize(input_data):\n",
        "\n",
        "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
        "    \n",
        "def denormalize(input_data):\n",
        "    input_data = (input_data + 1) * 127.5\n",
        "    return input_data.astype(np.uint8)\n",
        "   \n",
        " \n",
        "def load_path(path):\n",
        "    directories = []\n",
        "    if os.path.isdir(path):\n",
        "        directories.append(path)\n",
        "    for elem in os.listdir(path):\n",
        "        if os.path.isdir(os.path.join(path,elem)):\n",
        "            directories = directories + load_path(os.path.join(path,elem))\n",
        "            directories.append(os.path.join(path,elem))\n",
        "    return directories\n",
        "    \n",
        "def load_data_from_dirs(dirs, ext):\n",
        "    files = []\n",
        "    file_names = []\n",
        "    count = 0\n",
        "    for d in dirs:\n",
        "        for f in os.listdir(d): \n",
        "            if f.endswith(ext):\n",
        "                image = data.imread(os.path.join(d,f))\n",
        "                if len(image.shape) > 2:\n",
        "                    files.append(image)\n",
        "                    file_names.append(os.path.join(d,f))\n",
        "                    \n",
        "                count = count + 1\n",
        "    return files     \n",
        "\n",
        "def load_data(directory, ext):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    return files\n",
        "    \n",
        "def load_training_data(directory, ext, number_of_images = 1000, train_test_ratio = 0.8):\n",
        "\n",
        "    number_of_train_images = int(number_of_images * train_test_ratio)\n",
        "    \n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    test_array = array(files)\n",
        "    if len(test_array.shape) < 3:\n",
        "        print(\"Images are of not same shape\")\n",
        "        print(\"Please provide same shape images\")\n",
        "        sys.exit()\n",
        "    \n",
        "    x_train = files[:number_of_train_images]\n",
        "    x_test = files[number_of_train_images:number_of_images]\n",
        "    \n",
        "    x_train_hr = hr_images(x_train)\n",
        "    x_train_hr = normalize(x_train_hr)\n",
        "    \n",
        "    x_train_lr = lr_images(x_train, 4)\n",
        "    x_train_lr = normalize(x_train_lr)\n",
        "    \n",
        "    x_test_hr = hr_images(x_test)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(x_test, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
        "\n",
        "\n",
        "def load_test_data_for_model(directory, ext, number_of_images = 100):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    x_test_hr = hr_images(files)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(files, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_test_lr, x_test_hr\n",
        "    \n",
        "def load_test_data(directory, ext, number_of_images = 100):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    x_test_lr = lr_images(files, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_test_lr\n",
        "    \n",
        "# While training save generated image(in form LR, SR, HR)\n",
        "# Save only one image as sample  \n",
        "def plot_generated_images(output_dir, epoch, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    \n",
        "    examples = x_test_hr.shape[0]\n",
        "    print(examples)\n",
        "    value = randint(0, examples)\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 1)\n",
        "    plt.imshow(image_batch_lr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(dim[0], dim[1], 2)\n",
        "    plt.imshow(generated_image[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 3)\n",
        "    plt.imshow(image_batch_hr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir + 'generated_image_%d.png' % epoch)\n",
        "    \n",
        "    #plt.show()\n",
        "    \n",
        "# Plots and save generated images(in form LR, SR, HR) from model to test the model \n",
        "# Save output for all images given for testing  \n",
        "def plot_test_generated_images_for_model(output_dir, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    \n",
        "    examples = x_test_hr.shape[0]\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 1)\n",
        "        plt.imshow(image_batch_lr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(dim[0], dim[1], 2)\n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 3)\n",
        "        plt.imshow(image_batch_hr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'test_generated_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()\n",
        "\n",
        "# Takes LR images and save respective HR images\n",
        "def plot_test_generated_images(output_dir, generator, x_test_lr, figsize=(5, 5)):\n",
        "    \n",
        "    examples = x_test_lr.shape[0]\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        #plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE8GR87RR1MM"
      },
      "source": [
        "# Training code . Please change the output dir in the last line. According to where you want to save the weights. This has 500 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzToB57lROep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b7bd68-56ec-4417-ad46-403112e93b3b"
      },
      "source": [
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        "from skimage import data, io, filters\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy.random import randint\n",
        "#from scipy.misc import imread\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Subpixel Conv will upsample from (h, w, c) to (h/r, w/r, c/r^2)\n",
        "def SubpixelConv2D(input_shape, scale=4):\n",
        "    def subpixel_shape(input_shape):\n",
        "        dims = [input_shape[0],input_shape[1] * scale,input_shape[2] * scale,int(input_shape[3] / (scale ** 2))]\n",
        "        output_shape = tuple(dims)\n",
        "        return output_shape\n",
        "    \n",
        "    def subpixel(x):\n",
        "        return tf.depth_to_space(x, scale)\n",
        "        \n",
        "    return Lambda(subpixel, output_shape=subpixel_shape)\n",
        "    \n",
        "# Takes list of images and provide HR images in form of numpy array\n",
        "def hr_images(images):\n",
        "    images_hr = array(images)\n",
        "    return images_hr\n",
        "\n",
        "# Takes list of images and provide LR images in form of numpy array\n",
        "def lr_images(images_real , downscale):\n",
        "    \n",
        "    images= []\n",
        "    \n",
        "      \n",
        "    for img in  range(len(images_real)):\n",
        "        #images.append(cv2.resize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interpolation='bicubic', mode=None))\n",
        "        im123=cv2.resize(images_real[img], (int(images_real[img].shape[0]//downscale),int(images_real[img].shape[1]//downscale)))\n",
        "        images.append(im123)\n",
        "    images_lr = array(images)\n",
        "    return images_lr\n",
        "    \n",
        "def normalize(input_data):\n",
        "\n",
        "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
        "    \n",
        "def denormalize(input_data):\n",
        "    input_data = (input_data + 1) * 127.5\n",
        "    return input_data.astype(np.uint8)\n",
        "   \n",
        "\n",
        "    \n",
        "def load_training_data(x_train,y_train,x_test,y_test):\n",
        "\n",
        "    number_of_train_images = x_test.shape[0]\n",
        "    \n",
        "    #files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    #if len(files) < number_of_images:\n",
        "     #   print(\"Number of image files are less then you specified\")\n",
        "      #  print(\"Please reduce number of images to %d\" % len(files))\n",
        "       # sys.exit()\n",
        "        \n",
        "   # test_array = array(files)\n",
        "   # if len(test_array.shape) < 3:\n",
        "    #    print(\"Images are of not same shape\")\n",
        "     #   print(\"Please provide same shape images\")\n",
        "      #  sys.exit()\n",
        "    \n",
        "   \n",
        "\n",
        "    x_train_hr = hr_images(x_train)\n",
        "    x_train_hr = normalize(x_train_hr)\n",
        "    \n",
        "    x_train_lr = lr_images(x_train, 4)\n",
        "    x_train_lr = normalize(x_train_lr)\n",
        "    \n",
        "    x_test_hr = hr_images(x_test)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(x_test, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
        "\n",
        "\n",
        "    \n",
        "# While training save generated image(in form LR, SR, HR)\n",
        "# Save only one image as sample  \n",
        "def plot_generated_images(output_dir, epoch, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    print(\"In plot test generated images\")\n",
        "    examples = x_test_hr.shape[0]\n",
        "    print(examples)\n",
        "    value = randint(0, examples)\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 1)\n",
        "    plt.imshow(image_batch_lr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(dim[0], dim[1], 2)\n",
        "    plt.imshow(generated_image[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 3)\n",
        "    plt.imshow(image_batch_hr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir + 'generated_image_%d.png' % epoch)\n",
        "    \n",
        "    #plt.show()\n",
        "    \n",
        "# Plots and save generated images(in form LR, SR, HR) from model to test the model \n",
        "# Save output for all images given for testing  \n",
        "def plot_test_generated_images_for_model(output_dir, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    \n",
        "    examples = x_test_hr.shape[0]\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 1)\n",
        "        plt.imshow(image_batch_lr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(dim[0], dim[1], 2)\n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 3)\n",
        "        plt.imshow(image_batch_hr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'test_generated_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()\n",
        "\n",
        "# Takes LR images and save respective HR images\n",
        "def plot_test_generated_images(output_dir, generator, x_test_lr, figsize=(5, 5)):\n",
        "    \n",
        "    examples = x_test_lr.shape[0]\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        #plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)    \n",
        "    \n",
        "        #plt.show()\n",
        "\n",
        "###############################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "np.random.seed(10)\n",
        "# Better to use downscale factor as 4\n",
        "downscale_factor = 4\n",
        "# Remember to change image shape if you are having different size of images\n",
        "image_shape = (32,32,3)\n",
        "\n",
        "# Combined network\n",
        "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=shape)\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x) #Here I think there should be two inputs to discriminator x and another hr image\n",
        "    # and like this only the discriminator model should also be modified\n",
        "    gan = Model(inputs=gan_input, outputs=[x,gan_output])    #And why is there two outputs of the gan_model overall\n",
        "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
        "                loss_weights=[1., 1e-3],\n",
        "                optimizer=optimizer)\n",
        "\n",
        "    return gan\n",
        "\n",
        "# default values for all parameters are given, if want defferent values you can give via commandline\n",
        "# for more info use $python train.py -h\n",
        "def train(epochs, batch_size, x_train,y_train,x_test,y_test, model_save_dir):\n",
        "    \n",
        "    x_train_lr, x_train_hr, x_test_lr, x_test_hr = load_training_data(x_train,y_train,x_test,y_test) \n",
        "    loss = VGG_LOSS(image_shape)  \n",
        "    \n",
        "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
        "    shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
        "    \n",
        "    generator = Generator(shape).generator()\n",
        "    discriminator = Discriminator(image_shape).discriminator()\n",
        "\n",
        "    optimizer = get_optimizer()\n",
        "    generator.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "    \n",
        "    gan = get_gan_network(discriminator, shape, generator, optimizer, loss.vgg_loss)\n",
        "    \n",
        "    loss_file = open(model_save_dir + 'losses.txt' , 'w+')\n",
        "    loss_file.close()\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            \n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "           \n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "            print(image_batch_lr.shape)\n",
        "            generated_images_sr = generator.predict(image_batch_lr)\n",
        "\n",
        "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "            \n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
        "            discriminator_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            discriminator.trainable = False\n",
        "            gan_loss = gan.train_on_batch(image_batch_lr, [image_batch_hr,gan_Y])\n",
        "            \n",
        "            \n",
        "        print(\"discriminator_loss : %f\" % discriminator_loss)\n",
        "        print(\"gan_loss :\", gan_loss)\n",
        "        gan_loss = str(gan_loss)\n",
        "        \n",
        "        loss_file = open(model_save_dir + 'losses.txt' , 'a')\n",
        "        loss_file.write('epoch%d : gan_loss = %s ; discriminator_loss = %f\\n' %(e, gan_loss, discriminator_loss) )\n",
        "        loss_file.close()\n",
        "\n",
        "        if e == 1 or e % 5 == 0:\n",
        "            plot_generated_images(model_save_dir, e, generator, x_test_hr, x_test_lr)\n",
        "        if e % 1 == 0:\n",
        "            \n",
        "            generator.save(model_save_dir + 'gen_model%d.h5' % e)       \n",
        "            discriminator.save(model_save_dir + 'dis_model%d.h5' % e)\n",
        "            print(\"Model saved\")\n",
        "    \n",
        "train(1, 64, x_train,y_train,x_test,y_test, '/content/drive/My Drive/SRGAN/')                 #last parameter is to save the image to the path specified\n",
        "\n",
        "#train(no_of_epochs,batch_size,x_train,y_train,x_test,y_test,path_name of model saving)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/78 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 1 ---------------\n",
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|▏         | 1/78 [00:35<46:07, 35.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 2/78 [01:11<45:27, 35.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▍         | 3/78 [01:48<45:10, 36.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 4/78 [02:25<44:45, 36.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  6%|▋         | 5/78 [03:03<44:52, 36.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 6/78 [03:42<45:00, 37.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  9%|▉         | 7/78 [04:20<44:46, 37.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 8/78 [04:59<44:21, 38.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 12%|█▏        | 9/78 [05:36<43:27, 37.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 13%|█▎        | 10/78 [06:13<42:25, 37.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 14%|█▍        | 11/78 [06:49<41:20, 37.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 15%|█▌        | 12/78 [07:27<41:02, 37.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 13/78 [08:04<40:30, 37.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 18%|█▊        | 14/78 [08:41<39:37, 37.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 19%|█▉        | 15/78 [09:18<38:54, 37.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 21%|██        | 16/78 [09:55<38:12, 36.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 22%|██▏       | 17/78 [10:31<37:28, 36.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 23%|██▎       | 18/78 [11:08<36:44, 36.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 24%|██▍       | 19/78 [11:46<36:41, 37.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 26%|██▌       | 20/78 [12:24<36:09, 37.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 27%|██▋       | 21/78 [13:00<35:16, 37.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 28%|██▊       | 22/78 [13:37<34:32, 37.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 29%|██▉       | 23/78 [14:14<33:57, 37.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 31%|███       | 24/78 [14:51<33:16, 36.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 32%|███▏      | 25/78 [15:28<32:38, 36.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 26/78 [16:05<31:57, 36.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 35%|███▍      | 27/78 [16:41<31:19, 36.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 36%|███▌      | 28/78 [17:18<30:37, 36.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 37%|███▋      | 29/78 [17:55<30:03, 36.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 38%|███▊      | 30/78 [18:32<29:26, 36.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 40%|███▉      | 31/78 [19:09<29:00, 37.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 41%|████      | 32/78 [19:49<28:58, 37.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 42%|████▏     | 33/78 [20:27<28:31, 38.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 44%|████▎     | 34/78 [21:04<27:40, 37.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 45%|████▍     | 35/78 [21:41<26:51, 37.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 46%|████▌     | 36/78 [22:19<26:12, 37.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 47%|████▋     | 37/78 [22:56<25:35, 37.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 49%|████▊     | 38/78 [23:33<24:52, 37.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 39/78 [24:10<24:15, 37.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 51%|█████▏    | 40/78 [24:48<23:40, 37.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 53%|█████▎    | 41/78 [25:26<23:10, 37.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 54%|█████▍    | 42/78 [26:04<22:38, 37.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 55%|█████▌    | 43/78 [26:42<22:03, 37.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 56%|█████▋    | 44/78 [27:20<21:22, 37.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 58%|█████▊    | 45/78 [27:58<20:51, 37.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 59%|█████▉    | 46/78 [28:36<20:14, 37.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 60%|██████    | 47/78 [29:13<19:29, 37.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 62%|██████▏   | 48/78 [29:53<19:07, 38.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 63%|██████▎   | 49/78 [30:32<18:39, 38.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 64%|██████▍   | 50/78 [31:10<17:57, 38.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 65%|██████▌   | 51/78 [31:49<17:18, 38.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 52/78 [32:27<16:41, 38.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 68%|██████▊   | 53/78 [33:05<15:54, 38.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 69%|██████▉   | 54/78 [33:43<15:16, 38.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 71%|███████   | 55/78 [34:21<14:34, 38.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 72%|███████▏  | 56/78 [34:59<14:01, 38.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 73%|███████▎  | 57/78 [35:37<13:20, 38.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 74%|███████▍  | 58/78 [36:15<12:41, 38.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 76%|███████▌  | 59/78 [36:52<11:57, 37.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 77%|███████▋  | 60/78 [37:29<11:14, 37.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 78%|███████▊  | 61/78 [38:07<10:37, 37.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 79%|███████▉  | 62/78 [38:43<09:55, 37.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 81%|████████  | 63/78 [39:20<09:16, 37.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 82%|████████▏ | 64/78 [39:57<08:38, 37.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 65/78 [40:34<08:01, 37.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 85%|████████▍ | 66/78 [41:11<07:24, 37.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 86%|████████▌ | 67/78 [41:48<06:46, 36.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 87%|████████▋ | 68/78 [42:25<06:10, 37.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 69/78 [43:02<05:33, 37.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|████████▉ | 70/78 [43:39<04:56, 37.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 8, 8, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEDY70A0sTi5"
      },
      "source": [
        "def plot_test_generated_images_new(output_dir, generator, x_test_lr, figsize=(5, 5)):\n",
        "    \n",
        "    examples = 1\n",
        "    print(examples)\n",
        "    x_test_lr.resize(1,x_test_lr.shape[0],x_test_lr.shape[1],x_test_lr.shape[2])\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    generator.load_weights(output_dir + 'gen_model1.h5')\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        #plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)    \n",
        "    \n",
        "        plt.show()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyy7BCVWnxnP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "d1be62d8-b9d7-4c74-d02a-ef9770e3bfbf"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img=cv2.imread('/content/drive/My Drive/IMG_6086.jpg')\n",
        "\n",
        "#img.resize(1,img.shape[0],img.shape[1],img.shape[2])\n",
        "shape=img.shape\n",
        "#print(shape)\n",
        "generator = Generator(shape).generator()\n",
        "plot_test_generated_images_new('/content/drive/My Drive/SRGAN/', generator,img, figsize=(5, 5))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f71a5db2dffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#print(shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplot_test_generated_images_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/SRGAN/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ZghCdVJMHZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}